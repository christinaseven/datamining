#check the versions of libraries
#python version
import sys
print('Python: {}'.format(sys.version))
# scipy
import scipy
print('scipy: {}'.format(scipy.__version__))
# numpy
import numpy
print('numpy: {}'.format(numpy.__version__))
# matplotlib
import matplotlib
print('matplotlib: {}'.format(matplotlib.__version__))
# pandas
import pandas 
print('pandas: {}'.format(pandas.__version__))
# scikit-learn
import sklearn
print('sklearn: {}'.format(sklearn.__version__))
#load libraries
from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV
import pandas as pd
dataset = pd.read_csv("Seventikidou.csv", names=['c1', 'c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','target'])
dataset.head()
dataset.shape
# histograms
dataset.hist()
plt.show()
array=dataset.values
X = array[:,0:13]
Y = array[:,13]
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=1)
from sklearn.model_selection import KFold
import seaborn as sns
sns.pairplot(dataset,hue='target',palette='Dark2')
#first look
#create classifiers without care for hyperparameters to observe the results.
models = []
models.append(('KNN', KNeighborsClassifier()))
models.append(('DT', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))
results = []
names = []
for name, model in models:
	kfold = KFold(n_splits=10) #use 10 cross fold validation in the entire dataset & metric accuracy
	cv_results = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')
	results.append(cv_results)
	names.append(name)
	print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))
# Evaluating and predicting models

for name,model in models:
    trainedmodel = model.fit(X_train,Y_train)
    
    # prediction
    Y_pred = trainedmodel.predict(X_test)
    
    acc = accuracy_score(Y_test,Y_pred)
    classreport = classification_report(Y_test,Y_pred)
    
    print('\n****************************'+name)
    print('The accuracy: {}'.format(acc))
    print('The Classification Report:\n {}'.format(classreport))
#Create copy of dataset.
df_model = dataset.copy()
#select a scale method
#scaler = RobustScaler()
scaler = StandardScaler()
#scaler = MinMaxScaler()
features = [['c1', 'c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13']]
for feature in features:
    df_model[feature] = scaler.fit_transform(df_model[feature])

array=df_model.values
x = array[:,0:13]
y = array[:,13]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)

#Create KNN Object
# search for an optimal value of K for KNN
# list of integers 1 to 10 we want to try
k_range = range(1, 10)

# list of scores from k_range
k_scores = []

# 1. we will loop through reasonable values of k
for k in k_range:
    # 2. run KNeighborsClassifier with k neighbours
    knn = KNeighborsClassifier(n_neighbors=k)
    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours
    scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')
    # 4. append mean of scores for k neighbors to k_scores list
    k_scores.append(scores.mean())
print(k_scores)
#So finally we train a model based to these and evaluate the model
knnfinal = KNeighborsClassifier(n_neighbors=9, p=1)
knnfinal.fit(x_train,y_train)
y_predfinal = knnfinal.predict(x_test)
print('KNNfinalscore:')
print(accuracy_score(y_test, y_predfinal))
# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)
plt.plot(k_range, k_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Cross-Validated Accuracy')
#gridsearchcv
params_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9], 
              'p': [1, 2, 5]}
#define a dictionary of KNN parameters for the grid search. Here, we will consider K values between 3 and 7 
#and  p  values of 1 (Manhattan), 2 (Euclidean), and 5 (Minkowski).

gs_KNN = GridSearchCV(estimator=knn, 
                      param_grid=params_KNN, 
                      cv=10,
                      verbose=1,  # verbose: the higher, the more messages
                      scoring='accuracy', 
                      return_train_score=True)
gs_KNN.fit(x, y); #fit a KNN model using the full dataset.
gs_KNN.best_params_ #To get the best parameter values, we call the best_params_ attribute.
gs_KNN.best_score_
gs_KNN.cv_results_['mean_test_score']
#To extract more cross-validation results, we can call gs.csv_results - 
#a dictionary consisting of run details for each fold.
results_KNN = pd.DataFrame(gs_KNN.cv_results_['params'])
results_KNN['test_score'] = gs_KNN.cv_results_['mean_test_score']
results_KNN['metric'] = results_KNN['p'].replace([1,2,5], ["Manhattan", "Euclidean", "Minkowski"])
results_KNN
import altair as alt

alt.Chart(results_KNN, 
          title='KNN Performance Comparison'
         ).mark_line(point=True).encode(
    alt.X('n_neighbors', title='Number of Neighbors'),
    alt.Y('test_score', title='Mean CV Score', scale=alt.Scale(zero=False)),
    color='metric'
)
#naive bayes
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
#select a scale method
scaler = RobustScaler()
#scaler = StandardScaler()
#scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#Create a Gaussian Classifier
gnb = GaussianNB(priors=[0.5, 0.5])

#Train the model using the training sets
gnb.fit(X_train_scaled, Y_train)

#Predict the response for test dataset
y_pred_gnb = gnb.predict(X_test_scaled)
# Model Accuracy, how often is the classifier correct?
print("Accuracy of Naive Bayes:",metrics.accuracy_score(Y_test, y_pred_gnb))
steps = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4,1,5] 

nscores =[]
for step in steps:
    gnb = GaussianNB(priors=[0.5, 0.5], var_smoothing=step)
    scores1 = cross_val_score(gnb, X_train_scaled, Y_train, cv=10, scoring='accuracy')        
    nscores.append(scores1.mean())
print(nscores)
#Train the model
gnbfinal = GaussianNB(priors=[0.5, 0.5], var_smoothing=5)
gnbfinal.fit(X_train_scaled, Y_train)

#Predict the response for test dataset
y_pred_gnb = gnbfinal.predict(X_test_scaled)
# Model Accuracy, how often is the classifier correct?
print("Accuracy of NB final:",metrics.accuracy_score(Y_test, y_pred_gnb))
#create classifier 
from sklearn import svm
from sklearn import metrics

ls_scores = []
cs = [0.1, 1, 10, 100, 1000]
#cs = [1, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 100]

for c in cs:
    linear_svc = svm.SVC(kernel='linear', C=c)
    
    scores = cross_val_score(linear_svc, X_train_scaled, Y_train, cv=10, scoring='accuracy')
    # 4. append mean of scores list
    ls_scores.append(scores.mean())
print(ls_scores)

#Training the model
finallinear_svc = svm.SVC(kernel='linear', C=1)

finallinear_svc.fit(X_train_scaled, y_train)
#Predict testing set
Y_pred = finallinear_svc.predict(X_test_scaled)
#Check performance using accuracy
print('Accuracy of SVM linear final:',accuracy_score(Y_test, Y_pred))
from sklearn import svm

gammas = [0.1, 1, 10, 100]

rbf_scores = []


for gamma in gammas:
    svc = svm.SVC(kernel='rbf', gamma=gamma)
    
    scores = cross_val_score(svc, X_train_scaled, Y_train, cv=10, scoring='accuracy')
    # 4. append mean of scores l
    rbf_scores.append(scores.mean())
print(rbf_scores)
#Training the model
svc = svm.SVC(kernel='rbf', gamma=0.2)
svc.fit(X_train_scaled, y_train)
#Predict testing set
Y_pred = svc.predict(X_test_scaled)
#Check performance using accuracy
print('Accuracy of svm rbf:',accuracy_score(Y_test, Y_pred))
rbf_scores = []

cs = [1, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 100]

for c in cs:
    rbf_svc = svm.SVC(kernel='rbf', gamma=0.2, C=c)
    
    scores = cross_val_score(rbf_svc, X_train_scaled, Y_train, cv=10, scoring='accuracy')
    # 4. append mean of scores list
    rbf_scores.append(scores.mean())
print(rbf_scores)
#Training the model
svcfinal = svm.SVC(kernel='rbf', gamma=0.2, C=0.2)
svcfinal.fit(X_train_scaled, y_train)
#Predict testing set
Y_predsvcfinal = svc.predict(X_test_scaled)
#Check performance using accuracy
print('Accuracy of SVM rbf final:'accuracy_score(Y_test, Y_predsvcfinal))
#decision trees
de = [3, 7, 10, 20, 35,45,60,70,100]
clf_scores = []

for d in de:
    clf = DecisionTreeClassifier(criterion="entropy", max_depth=d)
    
    scores = cross_val_score(clf, X_train_scaled, Y_train, cv=10, scoring='accuracy')
    # 4. append mean of scores list
    clf_scores.append(scores.mean())
print(clf_scores)
# Train Decision Tree Classifer
clf = DecisionTreeClassifier(criterion="entropy", max_depth=20)

clf = clf.fit(X_train_scaled,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test_scaled)
print("Accuracy of decision trees final:",metrics.accuracy_score(y_test, y_pred))
